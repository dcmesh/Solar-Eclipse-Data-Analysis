{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gen_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "89b_fiXF1jQ4",
        "4WkSknI81jRz",
        "HRxWGL9-1jR1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcmesh/Solar-Eclipse-Data-Analysis/blob/main/gen_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWj1uk0S1jPl"
      },
      "source": [
        "# Festival of Frequency Measurement Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJMhRCkX1jQL"
      },
      "source": [
        "Colab by Joanna Elia based on Jupyter notebook by Kristina Collins KD8OXT, based on FFM code by Aidan Montare KB3UMD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNK6k1mI1jQQ"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6lezcNanyPv"
      },
      "source": [
        "First, we need to set up out virtual environment. \n",
        "\n",
        "Colab is missing some modules and some need to be updated. \n",
        "\n",
        "We also need to mount the drive, which will allow Colab to read and write files within your google drive.\n",
        "\n",
        "Uncomment the cell below and run it once before recommenting it out. Then restart the runtime (under the Runtime tab) so we can utilize the update modules.\n",
        "\n",
        "Then run the next cell to import all the modules we installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVc3zmmv2eGC"
      },
      "source": [
        "# run once if using Google Collabratory, this will take a while\n",
        "# uncomment first run, runtime needs to be restarted to use updated modules\n",
        "'''\n",
        "!pip install pyproj\n",
        "!pip install geopandas\n",
        "!pip install suntime\n",
        "!pip install -U plotly\n",
        "\n",
        "#git libaries used\n",
        "!pip install --user git+https://github.com/matplotlib/basemap.git\n",
        "!pip install --user git+https://github.com/HamSCI/eclipse_calculator.git\n",
        "\n",
        "#to grab Rise set Utils\n",
        "!wget 'https://raw.githubusercontent.com/dcmesh/Solar-Eclipse-Data-Analysis/main/Rise_set_utils.py'\n",
        "\n",
        "#to get files- specific to this dataset\n",
        "!wget https://zenodo.org/record/4400117/files/Freq_full.txt\n",
        "!wget https://zenodo.org/record/4400117/files/JEF_List.xlsx\n",
        "!wget https://zenodo.org/record/4400117/files/Vpk_full.txt\n",
        "\n",
        "#\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6MdVWCa1jQZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.collections as collections\n",
        "import matplotlib.dates\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "import pyproj\n",
        "import geopandas\n",
        "from geopy import distance\n",
        "from tqdm.notebook import tqdm\n",
        "from scipy import signal\n",
        "import itertools\n",
        "import plotly.graph_objects as go\n",
        "from plotly.validators.scatter.marker import SymbolValidator\n",
        "\n",
        "from mpl_toolkits.axes_grid1 import Divider, Size\n",
        "from mpl_toolkits.axes_grid1.mpl_axes import Axes\n",
        "\n",
        "from Rise_set_utils import midpoint\n",
        "\n",
        "# For correlations:\n",
        "import functools\n",
        "\n",
        "# register progress_apply with pandas\n",
        "tqdm.pandas(leave=False)\n",
        "\n",
        "# import necessary libraries for sunrise and sunset calculations:\n",
        "import datetime\n",
        "from datetime import timedelta\n",
        "from suntime import Sun, SunTimeException\n",
        "\n",
        "\n",
        "# Eclipse Obscuration Calc:\n",
        "%pylab inline\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "import eclipse_calc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tngrxeY41jQl"
      },
      "source": [
        "## Switches and Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJyozoju1jQn"
      },
      "source": [
        "# turn this on to generate the stackedplots\n",
        "# generally, leave this off to make the notebook run faster\n",
        "PLOT_STACKEDPLOTS = True\n",
        "\n",
        "# Turn this on to cull the data:\n",
        "CULL_DATA = True\n",
        "\n",
        "# turn this on to compute time-delayed correlations (which are pretty slow sometimes)\n",
        "COMPUTE_LARGE_CORRELATIONS = False\n",
        "\n",
        "# turn this on to load dask distributed client\n",
        "LOAD_DASK = False\n",
        "\n",
        "# turn this on to filter data\n",
        "FILTER_DATA = True\n",
        "\n",
        "# where the figures will be saved\n",
        "# must end with /\n",
        "if FILTER_DATA:\n",
        "    figures_dir = \"drive/Shared drives/Solar Eclipse Data Analysis/filtered_plots/\"\n",
        "else:\n",
        "    figures_dir = \"drive/Shared drives/Solar Eclipse Data Analysis/unfiltered_plots/\"\n",
        "\n",
        "\n",
        "start_day = datetime.date(2021, 6, 19)\n",
        "day_range = 3\n",
        "day = datetime.date(2020, 6, 21);\n",
        "\n",
        "# where data directory is located\n",
        "data_dir = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak7dvmLY1jQo"
      },
      "source": [
        "## Getting Started: Data Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V9BmXkR1jQq"
      },
      "source": [
        "Let's get some eclipse paths in here, since we'll be needing them soon:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoLU2ARA1jQx"
      },
      "source": [
        "# Get eclipse traces\n",
        "from urllib.request import urlopen\n",
        "import json\n",
        "with urlopen('https://hamsci.org/sites/default/files/eclipse/experiment/future-eclipses-custom.geojson') as response:\n",
        "    geojson = json.load(response)\n",
        "\n",
        "edf=pd.DataFrame()\n",
        "for i in range(9,17):\n",
        "    df2=[i, geojson[\"features\"][i][\"properties\"]['date'], geojson[\"features\"][i][\"properties\"]['EclipseProperty']]\n",
        "    df2=pd.DataFrame(df2)\n",
        "    df2=df2.T\n",
        "    columns=['id', 'date', 'type']\n",
        "    if edf.empty:\n",
        "        edf=df2\n",
        "    else:\n",
        "        edf=edf.append(df2)\n",
        "  \n",
        "edf.columns=['id', 'date', 'type']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svFUBMRS1jQ1"
      },
      "source": [
        "We can map the eclipse traces using either plotly or plotly express:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QXTb9wj1jQ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7594677f-97d7-40a1-f834-2adcbfe2395b"
      },
      "source": [
        "# Make an eclipse trace map\n",
        "fig = px.choropleth_mapbox(edf[0:1], geojson=geojson, color=\"date\",\n",
        "                           locations=\"date\", featureidkey=\"properties.date\",\n",
        "                           center={\"lat\": 20, \"lon\": 73.7073},\n",
        "                           mapbox_style=\"carto-positron\", zoom=2)\n",
        "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
        "fig.update(layout_showlegend=False)\n",
        "fig.show()\n",
        "\n",
        "fig = px.choropleth(edf, geojson=geojson, color=\"date\",\n",
        "                           locations=\"date\", featureidkey=\"properties.date\",\n",
        "                           center={\"lat\": 20, \"lon\": 73.7073},\n",
        "#                            mapbox_style=\"carto-positron\", zoom=2\n",
        "                   )\n",
        "fig.update_layout(margin={\"r\":0,\"t\":40,\"l\":40,\"b\":40})\n",
        "# fig.update(layout_showlegend=False)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0f76feaa70c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                            \u001b[0mlocations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatureidkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"properties.date\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"lat\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lon\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m73.7073\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                            mapbox_style=\"carto-positron\", zoom=2)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"l\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayout_showlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: choropleth_mapbox() got an unexpected keyword argument 'featureidkey'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szdfrgtg1jQ3"
      },
      "source": [
        "Next we read in the data. (Bonus points if we can figure out how to do this directly from Zenodo, but for now this notebook can link to the directory of the downloaded files.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPeJrAh9QXGe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvcZp2QV1jQ3"
      },
      "source": [
        "daystring='200'+str(day.month)+str(day.day)\n",
        "\n",
        "pedigree = pd.read_csv(data_dir + 'JEF Stations.csv')#, dtype={\"zID\": \"object\"})\n",
        "FreqError = pd.read_csv(data_dir + daystring +'_FreqErr.txt', index_col=0, parse_dates=['UTC'])\n",
        "Amplitude = pd.read_csv(data_dir + daystring + '_Vpk.txt', index_col=0, parse_dates=['UTC'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89b_fiXF1jQ4"
      },
      "source": [
        "## Set Up Data for Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsYljlqc1jQ6"
      },
      "source": [
        "The \"pedigree\" file contains metadata for each of the stations that collected 10 MHz data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIeAbZTX1jQ8",
        "scrolled": true
      },
      "source": [
        "# pedigree.loc([2])\n",
        "pedigree.loc[48,\"Callsign\"] = '罗 智文'\n",
        "pedigree.index_col = \"Callsign\"\n",
        "pedigree['Status'] = 'keep'\n",
        "pedigree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLKOu9LJ1jQ9"
      },
      "source": [
        "We should verify that all the collected datasets have pedigree entries. If FreqError has any columns not accounted for in pedigree, we're going to run into trouble. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c9mshv-1jQ-"
      },
      "source": [
        "(FreqError.columns).difference(pedigree.Callsign)\n",
        "FreqError=FreqError[pd.Index.intersection(FreqError.columns, pedigree.Callsign)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyI3mzAZ1jRA"
      },
      "source": [
        "Add sunrise and sunset times to our table. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmWJWe1e1jRB"
      },
      "source": [
        "for i in pedigree[\"Callsign\"].index.values:\n",
        "#     print(pedigree.loc[i,\"Callsign\"], pedigree.loc[i,\"Latitude\"], pedigree.loc[i,\"Longitude\"])\n",
        "    sun = Sun(pedigree.loc[i,\"Latitude\"], pedigree.loc[i,\"Longitude\"])\n",
        "#     abd = datetime.date(2020, 6, 21)\n",
        "    pedigree.loc[i,\"Sunrise\"] = sun.get_sunrise_time(day)\n",
        "    pedigree.loc[i,\"Sunset\"] = sun.get_sunset_time(day)\n",
        "pedigree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggNALtlH1jRD"
      },
      "source": [
        "The experimental data from all the stations is organized into tables - one for frequency error, one for amplitude, and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E7HpMr11jRE"
      },
      "source": [
        "FreqError.head()\n",
        "FreqError.columns\n",
        "\n",
        "#Adding filtering:\n",
        "filtered_FreqError = FreqError.rolling(window=300, min_periods=1).mean()\n",
        "unfiltered_FreqError = FreqError\n",
        "if FILTER_DATA:\n",
        "    FreqError=filtered_FreqError\n",
        "    Amplitude = Amplitude.rolling(window=300, min_periods=1).mean()\n",
        "    \n",
        "FreqError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcU7Hnon1jRG"
      },
      "source": [
        "FreqError.G0LHZ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj7cPeA91jRJ"
      },
      "source": [
        "Culling data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPazuA-w1jRJ"
      },
      "source": [
        "\n",
        "\n",
        "# pedigree.loc[pedigree[\"Callsign\"] == \"NU0C\"][\"Status\"] = \"remove\"\n",
        "\n",
        "if CULL_DATA==True:\n",
        "    for call in [\"3V1E\", \"K6RGI\", \"K6FOD\"]:\n",
        "        print(call)\n",
        "        #index = pedigree[pedigree[\"Callsign\"] == call]\n",
        "        list(pedigree[pedigree[\"Callsign\"] == call].index.values) \n",
        "        pedigree.loc[pedigree[pedigree[\"Callsign\"] == call].index.values, \"Status\"]  = \"remove\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1kD_Q061jRK"
      },
      "source": [
        "Some datasets were culled above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4HPokgW1jRL"
      },
      "source": [
        "We discussed which stations appear to have measurement errors on one of our Thursday telecon calls. The notes we generated are in the file `ffm-data-comments.txt`. Kristina also has her own version of this file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXdFt4zM1jRL"
      },
      "source": [
        "pedigree[pedigree[\"Status\"] == \"remove\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxTGdEZB1jRM"
      },
      "source": [
        "We can compare that list to the list I made, and indeed, they are the same list of stations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J1-7z-31jRN"
      },
      "source": [
        "Rather than outright removing the columns in `FreqError` corresponding to these stations, we'll replace their values with `nan`, the \"not a number\" value. We'll do this by creating a dataframe of booleans that we can use as a mask: every place with `True` will be kept for analysis, and every place with `False` will be replaced by `nan`.\n",
        "\n",
        "The advantage of doing this is that we can use the same procedure to mask out parts of a station's record. This will let us remove some of the errors in otherwise fine datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJLVFLG91jRO"
      },
      "source": [
        "# dataframe of positions that we will keep\n",
        "FreqErrorMask = FreqError.applymap(lambda x: True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_k2q96S1jRT"
      },
      "source": [
        "Set values as `False` for the stations we are going to remove."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsct-GWu1jRT"
      },
      "source": [
        "FreqErrorMask[pedigree[pedigree[\"Status\"] == \"remove\"][\"Callsign\"]] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j-qpGaw1jRV"
      },
      "source": [
        "And remove the portions of datasets that are otherwise fine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us_RuXhR1jRX"
      },
      "source": [
        "\n",
        "# FreqErrorMask.loc[\"2019-10-01T16:07\":\"2019-10-01T16:22\", \"VE6IXD\"] = False #3470110\n",
        "# FreqErrorMask.loc[\"2019-10-01T15:22\":\"2019-10-01T16:13\", \"K0ANS\"] = False #3468667\n",
        "# FreqErrorMask.loc[\"2019-10-01T23:15\":\"2019-10-02T00:00\", \"KA6WKE\"] = False #3468667"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykg1J3Oo1jRY"
      },
      "source": [
        "Here's our mask. It has the same columns and indicies as FreqError."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mldECHoy1jRY"
      },
      "source": [
        "FreqErrorMask.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZlwLAeP1jRZ"
      },
      "source": [
        "We can visualize the mask by creating an image of it. Below, light values (1's) are True, and dark values (0's )are False."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssdnWWZp1jRa"
      },
      "source": [
        "# sns.heatmap(FreqErrorMask.astype('int'))\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkgUM56g1jRa"
      },
      "source": [
        "To apply the mask, we use `.where`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA-EYLDw1jRa"
      },
      "source": [
        "# FreqError.where(FreqErrorMask).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eT6tazW1jRc"
      },
      "source": [
        "To check that the mask had the intended effect, let's make before and after images showing the location of `nan`'s in FreqError. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3Aigc6v1jRe"
      },
      "source": [
        "Before:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJGV8Z0W1jRe"
      },
      "source": [
        "sns.heatmap(FreqError.notna().astype('int'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InSZBOpQ1jRf"
      },
      "source": [
        "Note that even the original FreqError dataframe is missing a lot of values. Some of the data may have been eliminated because of the use of matlab's synchronise function to prepare the unified table in the zenodo upload.\n",
        "https://www.mathworks.com/help/matlab/ref/timetable.synchronize.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2dYFnW21jRh"
      },
      "source": [
        "After:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDMoiVBd1jRi"
      },
      "source": [
        "sns.heatmap(FreqError.where(FreqErrorMask).notna().astype('int'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsVw_Jcb1jRm"
      },
      "source": [
        "## combined before and after plot\n",
        "#\n",
        "#f, axes = plt.subplots(1,2, figsize=(14,6), sharey=True)\n",
        "#\n",
        "#sns.heatmap(FreqError.notna().astype('int'), ax=axes[0])\n",
        "#\n",
        "#sns.heatmap(FreqError.where(FreqErrorMask).notna().astype('int'), ax=axes[1])\n",
        "#\n",
        "#plt.subplots_adjust(top=0.7)\n",
        "#f.suptitle(\"Before and after the application of the mask\")\n",
        "#plt.tight_layout()\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1BUTTFx1jRn"
      },
      "source": [
        "Note these kinds of heatmaps also give us another way of visualizing the frequency error data. It doesn't seem as easy to read as the stackedplots, though."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5SgLjl91jRn"
      },
      "source": [
        "sns.heatmap(FreqError)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOkGOCzf1jRo"
      },
      "source": [
        "Now let's re-reun the correlations using our masked (we'll call it culled) dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYBq4wA21jRp"
      },
      "source": [
        "culled_FreqErrorCorrelations = FreqError.where(FreqErrorMask).corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtPB9nXE1jRs"
      },
      "source": [
        "culled_FreqErrorCorrelations.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGq42knV1jRt"
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(culled_FreqErrorCorrelations)\n",
        "plt.title(\"Correlations in (Culled, Raw) Frequency Error\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6op9JcY51jRt"
      },
      "source": [
        "\"They've gone to plaid!\" - KC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7N0Nc4y1jRu"
      },
      "source": [
        "The Festival of Frequency Measurement was 01 October 2019 0000 to 2359 UTC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6yTZZ5V1jRv"
      },
      "source": [
        "# date_timestamp = (pd.Timestamp(\"2019-10-01\")\n",
        "#                     .tz_localize(\"UTC\"))\n",
        "# date_string = date_timestamp.strftime(\"%Y-%m-%d\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsJmryuD1jRv"
      },
      "source": [
        "Since the data is ordered nicely, we could just plot the points in order and ignore any sort of time information. However, it will be much nicer if we use a datetime index for the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTJwGeLS1jRx"
      },
      "source": [
        "We now have datetime objects as the index:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m9CGnof1jRy"
      },
      "source": [
        "Amplitude.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WkSknI81jRz"
      },
      "source": [
        "## Bare basics\n",
        "\n",
        "Let's just plot one of the stations' data. Local sunrise is the dotted line, sunset the solid one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwWXKuJ41jR0"
      },
      "source": [
        "Callsign=\"G0LHZ\"\n",
        "# pandas has some convient plotting functions built in, although datetimes are tricky.\n",
        "# sr=pedigree.loc[pedigree[pedigree[\"Callsign\"] == Callsign].index.values, \"Sunrise\"]\n",
        "# sr=sr.values[0]\n",
        "# ss=pedigree.loc[pedigree[pedigree[\"Callsign\"] == Callsign].index.values, \"Sunset\"]\n",
        "# ss=ss.values[0]\n",
        "\n",
        "FreqError[Callsign].plot()\n",
        "# plt.axvline(x=sr, ymin=-1, ymax=1, ls='--', color=[1, 0, 0])\n",
        "# plt.axvline(x=ss, ymin=-1, ymax=1, ls='-', color=[1, 0, 0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRxWGL9-1jR1"
      },
      "source": [
        "## Organize Data Geographically"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksa8moDTvhb1"
      },
      "source": [
        "###Using Plotly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djyWN9WX1jR2"
      },
      "source": [
        "From the latitude and longitude data, we can make a map of where the stations are. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P5qeKMG1jR3"
      },
      "source": [
        "linklist ='https://qrz.com/db/'+pedigree[\"Callsign\"]\n",
        "clicklist = str('<')+str('a href=')+str('\"\\\"') + linklist+ str('/\\>') + pedigree[\"Callsign\"]\n",
        "fig = px.scatter_geo(pedigree, \"Latitude\", \"Longitude\",\n",
        "                     color=\"GPSDO\", # which column to use to set the color of markers\n",
        "                     hover_name=pedigree[\"Callsign\"],#clicklist,#, # column added to hover information\n",
        "#                      projection = 'albers usa',\n",
        "                     )\n",
        "fig.update_layout(title=\"Stations Submitting Data to the June Eclipse Festival\")\n",
        "fig.show()\n",
        "fig.write_html(figures_dir +\"stationmap.html\") #export as html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL4Qrr-j1jR5"
      },
      "source": [
        "Plotly Express is incredibly handy, but it only uses dots. For printing in black and white we need a version with different marker types. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzHI2iBj1jR5"
      },
      "source": [
        "df = pedigree\n",
        "df.loc[48,\"Callsign\"] = 'SWL-02'\n",
        "# from plotly.validators.scatter.marker import SymbolValidator\n",
        "WWVlat = [40.678306]\n",
        "WWVlong = [-105.040889]\n",
        "\n",
        "markerlist=0+(df['GPSDO'].values == \"Yes\")\n",
        "namelist = df['GPSDO'].values\n",
        "\n",
        "#markerlist\n",
        "fig = go.Figure(data=go.Scattergeo(\n",
        "#         projection ='albers usa',\n",
        "        locationmode = 'ISO-3',\n",
        "        lon = df['Longitude'],\n",
        "        lat = df['Latitude'],\n",
        "        text = df['Callsign'],\n",
        "        mode = 'markers',\n",
        "        marker = dict(\n",
        "            size = 8,\n",
        "            opacity = 0.8,\n",
        "            reversescale = True,\n",
        "            autocolorscale = False,\n",
        "            symbol=markerlist,\n",
        "#             colorscale=[[0, \"rgb(166,206,227)\"],[0.25, \"rgb(31,120,180)\"]],\n",
        "            color = (markerlist+2)\n",
        "        )\n",
        "))\n",
        "\n",
        "# Plot WWV:\n",
        "fig.add_trace(go.Scattergeo(\n",
        "        mode=\"markers+lines\",\n",
        "        lon=WWVlong,\n",
        "        lat=WWVlat,\n",
        "        name=\"WWV\",\n",
        "        marker={'size': 20,\n",
        "               'color': 'Black',\n",
        "                'line.color':'Orange',\n",
        "               'symbol': 'star'}))\n",
        "\n",
        "\n",
        "fig.update_layout(coloraxis = {'colorscale':'viridis'})\n",
        "fig.update_layout(\n",
        "#         title = 'Festival of Frequency Measurement Stations<br>',\n",
        "        geo = dict(\n",
        "            scope='world',\n",
        "#             projection_type='albers usa',\n",
        "            showland = True,\n",
        "            landcolor = \"rgb(250, 250, 250)\",\n",
        "            subunitcolor = \"rgb(90, 90, 90)\",\n",
        "            countrycolor = \"rgb(217, 217, 217)\",\n",
        "            countrywidth = 0.5,\n",
        "            subunitwidth = 0.5\n",
        "        )\n",
        "\n",
        "    )\n",
        "\n",
        "fig.update_layout(legend_title_text='GPSDO')\n",
        "fig.update_layout(showlegend=False)\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# fig.savefig('printmap.png')\n",
        "# fig.write_image(figures_dir + \"printmap.png\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLO36-_V1jR6"
      },
      "source": [
        "Let's make a map of the stations with the relevant eclipse trace in it: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihoZxtIO1jR7"
      },
      "source": [
        "df = pedigree\n",
        "# df.loc[48,\"Callsign\"] = 'SWL-02'\n",
        "# from plotly.validators.scatter.marker import SymbolValidator\n",
        "WWVlat = [40.678306]\n",
        "WWVlong = [-105.040889]\n",
        "\n",
        "markerlist=0+(df['GPSDO'].values == \"Yes\")\n",
        "namelist = df['GPSDO'].values\n",
        "\n",
        "#fig = px.choropleth(edf[0:1], geojson=geojson, color=\"date\", locations=\"date\", featureidkey=\"properties.date\",center={\"lat\": 0, \"lon\": 90})\n",
        "#                            mapbox_style=\"carto-positron\", zoom=2\n",
        "                           \n",
        "\n",
        "# fig = go.Figure(data=go.Choropleth(\n",
        "#     locations=edf['date'],\n",
        "# #     z=df['total exports'].astype(float),\n",
        "# #     locationmode='USA-states',\n",
        "# #     colorscale='Reds',\n",
        "# #     autocolorscale=False,\n",
        "# #     text=df['text'], # hover text\n",
        "# #     marker_line_color='white', # line markers between states\n",
        "# #     colorbar_title=\"Millions USD\"\n",
        "# ))\n",
        "\n",
        "# fig.update(layout_showlegend=False)\n",
        "#markerlist\n",
        "\n",
        "fig.add_trace(go.Scattergeo(\n",
        "#         projection ='albers usa',\n",
        "        locationmode = 'ISO-3',\n",
        "        lon = df['Longitude'],\n",
        "        lat = df['Latitude'],\n",
        "        text = df['Callsign'],\n",
        "        mode = 'markers',\n",
        "        name = '',\n",
        "        marker = dict(\n",
        "            size = 8,\n",
        "            opacity = 0.8,\n",
        "            reversescale = True,\n",
        "            autocolorscale = False,\n",
        "            symbol=markerlist,\n",
        "#             colorscale=[[0, \"rgb(166,206,227)\"],[0.25, \"rgb(31,120,180)\"]],\n",
        "            color = (markerlist+2)\n",
        "        )\n",
        "))\n",
        "\n",
        "# Plot WWV:\n",
        "fig.add_trace(go.Scattergeo(\n",
        "        mode=\"markers+lines\",\n",
        "        lon=WWVlong,\n",
        "        lat=WWVlat,\n",
        "        name=\"WWV\",\n",
        "        marker={'size': 20,\n",
        "               'color': 'Black',\n",
        "                'line.color':'Orange',\n",
        "               'symbol': 'star'}))\n",
        "\n",
        "# Plot BPM:\n",
        "fig.add_trace(go.Scattergeo(\n",
        "        mode=\"markers+lines\",\n",
        "        lon=[109.543036],\n",
        "        lat=[34.948878],\n",
        "        name=\"BPM\",\n",
        "        marker={'size': 20,\n",
        "               'color': 'Black',\n",
        "                'line.color':'Orange',\n",
        "               'symbol': 'star'}))\n",
        "\n",
        "\n",
        "fig.update_layout(coloraxis = {'colorscale':'viridis'})\n",
        "# fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
        "fig.update_layout(\n",
        "#         title = 'Festival of Frequency Measurement Stations<br>',\n",
        "        geo = dict(\n",
        "            scope='world',\n",
        "#             projection_type='albers usa',\n",
        "            showland = True,\n",
        "            landcolor = \"rgb(250, 250, 250)\",\n",
        "            subunitcolor = \"rgb(90, 90, 90)\",\n",
        "            countrycolor = \"rgb(217, 217, 217)\",\n",
        "            countrywidth = 0.5,\n",
        "            subunitwidth = 0.5\n",
        "        )\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"June Eclipse Stations\",\n",
        "    legend_title=\"Legend Title\",\n",
        "#     labels={\"date\":\"GPSDO Stations\"}\n",
        "    \n",
        "#     font=dict(\n",
        "#         family=\"Courier New, monospace\",\n",
        "#         size=18,\n",
        "#         color=\"RebeccaPurple\"\n",
        "#     )\n",
        ")\n",
        "\n",
        "# fig.update_layout(legend_title_text='GPSDO')\n",
        "fig.update_layout(showlegend=False)\n",
        "fig.update_layout(height=800, width=1800, margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
        "fig.show()\n",
        "fig.write_html(figures_dir +\"junemap.html\") #export as html\n",
        "# fig.savefig('printmap.png')\n",
        "# fig.write_image(figures_dir + \"junemap.png\")\n",
        "\n",
        "#df.loc[47:48]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8KGIkjKJJdJ"
      },
      "source": [
        "fig1 = px.choropleth(edf[0:1], geojson=geojson, color=\"date\", locations=\"date\", featureidkey=\"properties.date\",center={\"lat\": 0, \"lon\": 90})\n",
        "fig1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb-9aNptvome"
      },
      "source": [
        "###Using Matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-wCaZhI1jR7"
      },
      "source": [
        "We can then rearrange the stations according to longitude (and latitude, secondarily) and put the culled stations at the end. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQYXgAJb1jR7"
      },
      "source": [
        "pedigree.sort_values(by=['Status', 'Longitude', 'Latitude'], ascending=[1, 0, 1], inplace=True)\n",
        "# FreqError = FreqError[pedigree[\"Callsign\"].astype(str)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5k1xgzn1jSA"
      },
      "source": [
        "We'll create the stackedplot using matplotlib. First we'll generate a tiny map for each station that we can include in the stackedplot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pvFeRl51jSA"
      },
      "source": [
        "gdf = geopandas.GeoDataFrame(pedigree, geometry=geopandas.points_from_xy(pedigree[\"Longitude\"], pedigree[\"Latitude\"]))\n",
        "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6BT2Wqb1jSC"
      },
      "source": [
        "# ax = world.cx[-120:-60,20:70].plot( #North America only\n",
        "ax = world.cx[-180:180,-90:90].plot(\n",
        "    color='white', edgecolor='black')\n",
        "\n",
        "# We can now plot our ``GeoDataFrame``.\n",
        "gdf.plot(ax=ax, color='red')\n",
        "\n",
        "#px.choropleth(edf[0:1], geojson=geojson, color=\"date\", locations=\"date\", featureidkey=\"properties.date\",center={\"lat\": 0, \"lon\": 90})\n",
        "#plt.show()\n",
        "edf[0:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCX_19uu1jSC"
      },
      "source": [
        "If we want to check any of the parameters of gdf:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8SwCAaN1jSD"
      },
      "source": [
        "gdf.head()\n",
        "gdf.dtypes\n",
        "gdf.shape\n",
        "pedigree.shape\n",
        "gdf.total_bounds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMQziXgHCvC5"
      },
      "source": [
        "##Stacked Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or_R5TVZvzpd"
      },
      "source": [
        "###Sample Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pcKKIdE1jSE"
      },
      "source": [
        "Callsign=\"3V1E\"    \n",
        "# Create a vector of times to evaluate\n",
        "sTime = datetime.datetime(2020,6,21,0,0)#(2017,8,21,16,0)\n",
        "eTime = datetime.datetime(2020,6,21,23,0)#(2017,8,21,20,0)\n",
        "dt    = datetime.timedelta(minutes=5)\n",
        "q=1\n",
        "\n",
        "times = [sTime]\n",
        "while times[-1] < eTime:\n",
        "  times.append(times[-1]+dt)\n",
        "  q+=1\n",
        "#obscuration calcs:\n",
        "record = gdf[gdf[\"Callsign\"] == Callsign].iloc[0]\n",
        "obsc  = eclipse_calc.calculate_obscuration(times,record.Latitude,record.Longitude)\n",
        "x = matplotlib.dates.date2num(times)\n",
        "yarr = vstack((obsc,))\n",
        "\n",
        "\n",
        "# pandas has some convient plotting functions built in, although datetimes are tricky.\n",
        "fig, ax = plt.subplots()\n",
        "axs = [ax, ax.twinx()]\n",
        "\n",
        "sr=pedigree.loc[pedigree[pedigree[\"Callsign\"] == Callsign].index.values, \"Sunrise\"]\n",
        "sr=sr.values[0]\n",
        "ss=pedigree.loc[pedigree[pedigree[\"Callsign\"] == Callsign].index.values, \"Sunset\"]\n",
        "ss=ss.values[0]\n",
        "\n",
        "axs[1].plot(FreqError[Callsign])\n",
        "axs[0].imshow(yarr, extent = [min(x),max(x), -1, 1], aspect = 'auto', cmap= 'binary')\n",
        "axs[0].axes.get_yaxis().set_visible(False)\n",
        "fig.autofmt_xdate()\n",
        "\n",
        "\n",
        "plt.axvline(x=sr, ymin=-1, ymax=1, ls='--', color=[1, 0, 0])\n",
        "plt.axvline(x=ss, ymin=-1, ymax=1, ls='-', color=[1, 0, 0])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-btZd01wSll"
      },
      "source": [
        "####Using Plotly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6Ai3sutvK6n"
      },
      "source": [
        "Here is the same graph, but with plotly. It runs slower"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNuyrL651jSZ"
      },
      "source": [
        "px.line(FreqError, x=FreqError.index, y=\"G0LHZ\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz-msJdUv6D3"
      },
      "source": [
        "###Stacked Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "227Vg1t41jSF"
      },
      "source": [
        "Now let's create that stackedplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHgnBkPg1jSG"
      },
      "source": [
        "def suplabel(axis,label,label_prop=None,\n",
        "             labelpad=5,\n",
        "             ha='center',va='center'):\n",
        "    ''' Add super ylabel or xlabel to the figure\n",
        "    Similar to matplotlib.suptitle\n",
        "    axis       - string: \"x\" or \"y\"\n",
        "    label      - string\n",
        "    label_prop - keyword dictionary for Text\n",
        "    labelpad   - padding from the axis (default: 5)\n",
        "    ha         - horizontal alignment (default: \"center\")\n",
        "    va         - vertical alignment (default: \"center\")\n",
        "    \n",
        "    from https://stackoverflow.com/a/29107972/10008497\n",
        "    '''\n",
        "    fig = plt.gcf()\n",
        "    xmin = []\n",
        "    ymin = []\n",
        "    for ax in fig.axes:\n",
        "        xmin.append(ax.get_position().xmin)\n",
        "        ymin.append(ax.get_position().ymin)\n",
        "    xmin,ymin = min(xmin),min(ymin)\n",
        "    dpi = fig.dpi\n",
        "    if axis.lower() == \"y\":\n",
        "        rotation=90.\n",
        "        x = xmin-float(labelpad)/dpi\n",
        "        y = 0.5\n",
        "    elif axis.lower() == 'x':\n",
        "        rotation = 0.\n",
        "        x = 0.5\n",
        "        y = ymin - float(labelpad)/dpi\n",
        "    else:\n",
        "        raise Exception(\"Unexpected axis: x or y\")\n",
        "    if label_prop is None: \n",
        "        label_prop = dict()\n",
        "    plt.text(x,y,label,rotation=rotation,\n",
        "               transform=fig.transFigure,\n",
        "               ha=ha,va=va,\n",
        "               **label_prop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9MrlOAc1jSG"
      },
      "source": [
        "Here's the function we'll use to make stackplots. It includes sunrise and sunset times and maps for each station."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bsmXuVI1jSI"
      },
      "source": [
        "from mpl_toolkits.axes_grid1 import Divider, Size\n",
        "from mpl_toolkits.axes_grid1.mpl_axes import Axes\n",
        "\n",
        "#debugging previous cell...\n",
        "def stackedplot2(df, n=None, start=0, sharey=False, amplitude_df=None, mask_df=None, date_limit=None):\n",
        "    \"\"\"\n",
        "    Make a stacked plot for the first n columns in df.\n",
        "    \n",
        "    stackedplot2 uses matplotlib, and won't lock up the computer\n",
        "    forever. Just a while.\n",
        "    \n",
        "    Returns a figure object.\n",
        "    \n",
        "    start: the first index to plot (default: 0)\n",
        "    n: the number of columns to plot (default: all the columns)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    if n is None:\n",
        "        n = df.columns.size\n",
        "        \n",
        "    if mask_df is not None:\n",
        "        fill_df = ~mask_df\n",
        "    \n",
        "    fig, axes = plt.subplots(nrows=n, ncols=3, sharey=sharey, \n",
        "#                               sharex='col', #comment out to change maps\n",
        "                             gridspec_kw={'width_ratios': [4, 1, 1]})\n",
        "    \n",
        "    world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
        "    padding = 10\n",
        "\n",
        "    # comment out these 2 lines:\n",
        "#     ax = world.cx[-120:-60,20:70].plot(ax=axes[i,1],\n",
        "#        color='white', edgecolor='black')\n",
        "    \n",
        "    i=0\n",
        "    previous_amplitude_axis = None\n",
        "    \n",
        "    for Callsign in tqdm(df.columns[start:(start + n)], desc=\"Making stackedplot\"):\n",
        "# #     Full world map\n",
        "        mapbounds = [-180,   180  ,  -90,   90]\n",
        "\n",
        "        # data\n",
        "        sr=pedigree.loc[pedigree[pedigree[\"Callsign\"] == Callsign].index.values, \"Sunrise\"]\n",
        "        sr=sr.values[0]\n",
        "#         print('Sunrise for ', Callsign, sr)\n",
        "        ss=pedigree.loc[pedigree[pedigree[\"Callsign\"] == Callsign].index.values, \"Sunset\"]\n",
        "        ss=ss.values[0]\n",
        "        print('Sunset for ', Callsign, ss)\n",
        "        \n",
        "        # ECLIPSE OBSCURATION:\n",
        "        # Create a vector of times to evaluate\n",
        "        sTime = datetime.datetime(2020,6,21,0,0)#(2017,8,21,16,0)\n",
        "        eTime = datetime.datetime(2020,6,22,0,0)#(2017,8,21,20,0)\n",
        "        dt    = datetime.timedelta(minutes=5)\n",
        "        q=1\n",
        "\n",
        "        times = [sTime]\n",
        "        while times[-1] < eTime:\n",
        "            times.append(times[-1]+dt)\n",
        "            q+=1\n",
        "        #obscuration calcs:\n",
        "        record = gdf[gdf[\"Callsign\"] == Callsign].iloc[0]\n",
        "        obsc   = eclipse_calc.calculate_obscuration(times,record.Latitude,record.Longitude)\n",
        "        x2     = matplotlib.dates.date2num(times)\n",
        "        yarr   = vstack((obsc,)) \n",
        "\n",
        "        # obscuration code needs to be on first axis otherwise it covers the plot\n",
        "        axes[i,0].imshow(yarr, extent = [min(x2),max(x2), -1, 1], aspect = 'auto', cmap= 'binary')\n",
        "        axes[i,0].axes.get_yaxis().set_visible(False)\n",
        "        axes[i,0].axes.get_xaxis().set_visible(False)\n",
        "\n",
        "        freq_axis = axes[i,0].twinx()\n",
        "        freq_axis.plot(df[Callsign])\n",
        "        freq_axis.axvline(x=sr, ymin=-1, ymax=1, ls='--', color=[1, 0, 0])\n",
        "        freq_axis.axvline(x=ss, ymin=-1, ymax=1, ls='-', color=[1, 0, 0])    \n",
        "        freq_axis.get_xaxis().set_visible(False) \n",
        "        \n",
        "        axes[i,0].grid(False)\n",
        "        freq_axis.grid(False)\n",
        "\n",
        "        #testing this...\n",
        "        if date_limit is not None:\n",
        "#             foo = axes[i, 0].set_xlim([737962, 737963])\n",
        "            foo = axes[i, 0].set_xlim([day, day+timedelta(1)])\n",
        "#         print(axes[i, 0].get_xlim())\n",
        "        \n",
        "        if amplitude_df is not None:\n",
        "            amplitude_axis = freq_axis.twinx()\n",
        "            amplitude_axis.plot(amplitude_df[Callsign], 'r')\n",
        "            if sharey == 'col' and i != 0: \n",
        "                #print(i, previous_amplitude_axis, amplitude_axis)\n",
        "                amplitude_axis.get_shared_y_axes().join(amplitude_axis, previous_amplitude_axis)\n",
        "                #print(i, amplitude_axis.get_shared_y_axes().get_siblings(amplitude_axis))\n",
        "            previous_amplitude_axis = amplitude_axis\n",
        "            amplitude_axis.grid(False)\n",
        "        \n",
        "        if mask_df is not None:\n",
        "            limits = axes[i,0].get_ylim()\n",
        "            axes[i,0].fill_between(df.index, limits[0], limits[1], where=fill_df[Callsign],\n",
        "                                   color=\"white\", alpha=1)\n",
        "            # see https://github.com/matplotlib/matplotlib/issues/3872\n",
        "            #collection = collections.BrokenBarHCollection.span_where(\n",
        "            #    df.index, ymin=0, ymax=1, where=mask_df[zID], facecolor='green', alpha=0.5)\n",
        "            #ax.add_collection(collection)\n",
        "        # TODO make time scale visible\n",
        "\n",
        "        # location map\n",
        "        world.cx[-180:180,-90:90].plot(ax=axes[i,1],\n",
        "            color='white', edgecolor='black')\n",
        "        gdf[gdf[\"Callsign\"] == Callsign].plot(ax=axes[i,1], color='red')\n",
        "#         axes[i,1].set_xlim(mapbounds[0] - padding, mapbounds[2] + padding)\n",
        "#         axes[i,1].set_ylim(mapbounds[1] - padding, mapbounds[3] + padding)\n",
        "        axes[i,1].tick_params(labelleft=False, labelbottom=False)\n",
        "        \n",
        "        # station info\n",
        "        record = gdf[gdf[\"Callsign\"] == Callsign].iloc[0]\n",
        "        text = (\"Callsign: {callsign}\\n\"\n",
        "#                 \"Status: {status}\\n\"\n",
        "                \"Latitude: {latitude:.4}\\n\"\n",
        "                \"Longitude: {longitude:.4}\\n\"\n",
        "                \"GPSDO: {gpsdo}\").format(callsign=record.Callsign,\n",
        "                                          status=record.Status,\n",
        "                                          latitude=record.Latitude,\n",
        "                                          longitude=record.Longitude,\n",
        "                                          gpsdo=record[\"GPSDO\"])\n",
        "        axes[i, 2].text(0, 0, text)\n",
        "        axes[i, 2].axis('off')\n",
        "        i+=1\n",
        "        \n",
        "    #axes[n - 1, 0].get_xaxis().set_major_locator(matplotlib.dates.HourLocator(interval=3))\n",
        "    \n",
        "    axes[n - 1, 0].get_xaxis().set_major_formatter(matplotlib.dates.DateFormatter('%m/%d %H:%M'))\n",
        "    plt.setp(axes[n-1,0].get_xticklabels(), rotation=30, ha=\"right\")\n",
        "        \n",
        "    axes[n-1, 0].get_xaxis().set_visible(True) #testing this...\n",
        "    \n",
        "    axes[0, 0].set_title(\"Submitted Frequency Data\")\n",
        "    axes[0, 1].set_title(\"Map\")\n",
        "    axes[0, 2].set_title(\"Info\")\n",
        "    \n",
        "    axes[n - 1, 0].set_xlabel(\"Time (UTC)\")\n",
        "    \n",
        "    #axes[n//2, 0].set_ylabel(\"Frequency Deviation\", rotation=\"vertical\")\n",
        "\n",
        "    suplabel(\"y\", \"Frequency Deviation (Hz)\")\n",
        "    \n",
        "    #fig.text(0, 0, \"Frequency Deviation (Hz)\", ha=\"center\", va=\"center\", rotation=\"vertical\")\n",
        "    \n",
        "    return fig\n",
        "    gdf[gdf[\"Callsign\"] == Callsign].iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRkJkYtB1jSJ"
      },
      "source": [
        "Let's test this out with a small set of plots. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH1xFSFC1jSJ",
        "scrolled": false
      },
      "source": [
        "fig = stackedplot2(FreqError, n=5, start=5, mask_df=FreqErrorMask, amplitude_df=Amplitude, date_limit='None')\n",
        "print('Figure created.')\n",
        "fig.set_size_inches(12,6)\n",
        "fig.savefig(figures_dir + daystring + \"_sample-stackedplot.png\", bbox_inches=\"tight\", pad_inches=0)\n",
        "print('Figure written.')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36hiyoXE1jSK"
      },
      "source": [
        "Here's where we generate the split stackedplot so it can be printed easily on a single page. This cell will take a while to run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DefCmHk31jSO"
      },
      "source": [
        "if PLOT_STACKEDPLOTS:\n",
        "    # make the two-columns layout for paper\n",
        "    first_in_column_two = int(np.ceil(FreqError.columns.size/2))\n",
        "    sizes = [first_in_column_two, FreqError.columns.size - first_in_column_two]\n",
        "    print(sizes)\n",
        "    \n",
        "    fig1 = stackedplot2(FreqError, n=sizes[1], start=1, mask_df=FreqErrorMask, amplitude_df=Amplitude, date_limit='None')# date_limit=1)\n",
        "    fig1.set_size_inches(12,24)\n",
        "#     fig.tight_layout()\n",
        "    fig1.savefig(figures_dir + daystring+\"_stackedplot-split-1.png\", bbox_inches=\"tight\", pad_inches=0)\n",
        "    \n",
        "    fig2 = stackedplot2(FreqError, n=sizes[1], start=first_in_column_two, mask_df=FreqErrorMask, amplitude_df=Amplitude, date_limit='None')#, date_limit=1)\n",
        "    fig2.set_size_inches(12,24)\n",
        "    #fig2.savefig('paper-stackedplot-split-2.png')\n",
        "    #fig.tight_layout()\n",
        "    fig2.savefig(figures_dir + daystring + \"_stackedplot-split-2.png\", bbox_inches=\"tight\", pad_inches=0)\n",
        "#     FreqError=qux"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnh1OLALRWi2"
      },
      "source": [
        "##Eclipse Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpCMzZtJrkyT"
      },
      "source": [
        "This code that creates an Eclipse Map is separate from the rest of the notebook. It is https://github.com/HamSCI/eclipse_calculator/blob/master/eclipse_maps.py with different dates. \n",
        "\n",
        "If you only want to create the eclipse map, run these two cells, make sure to uncomment the installs in the first cell, if the code in the Intro wasn't run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dowRmMA2ufS7"
      },
      "source": [
        "###TODO change eclipse_maps.py to a function with parameters of start and end time and interval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPpGnY_fRuMD"
      },
      "source": [
        "\"\"\"\n",
        "#git libaries used\n",
        "!pip install --user git+https://github.com/matplotlib/basemap.git\n",
        "!pip install --user git+https://github.com/HamSCI/eclipse_calculator.git\n",
        "\n",
        "#mount drive to get data from and save files to\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doHt5W_IRZ8s"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import datetime\n",
        "from collections import OrderedDict\n",
        "import multiprocessing\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib as mpl\n",
        "mpl.use(\"Agg\")\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from astropy.coordinates import EarthLocation\n",
        "\n",
        "import eclipse_calc\n",
        "\n",
        "def location_dict(precision=2,height=0.):\n",
        "    gs_grid     = eclipse_calc.locator.gridsquare_grid(precision=precision).flatten()\n",
        "    ll_grid     = eclipse_calc.locator.gridsquare2latlon(gs_grid)\n",
        "    lats,lons   = ll_grid\n",
        "\n",
        "    dd              = OrderedDict()\n",
        "    dd['grid']      = gs_grid\n",
        "    dd['lat']       = lats\n",
        "    dd['lon']       = lons\n",
        "    dd['height']    = np.ones(lats.shape)*height\n",
        "#    dd['loc']   = [EarthLocation.from_geodetic(lon,lat,height) for lat,lon in zip(lats,lons)]\n",
        "    return dd\n",
        "\n",
        "def plot_eclipse_dict(run_dict):\n",
        "    return plot_eclipse(**run_dict)\n",
        "\n",
        "def plot_eclipse(date,loc_dict,region='world',cmap=mpl.cm.gray_r,output_dir='output'):\n",
        "    \"\"\"\n",
        "    region: 'us' or 'world\"\n",
        "    height: [km]\n",
        "    \"\"\"\n",
        "    # Define output paths.\n",
        "    date_str    = date.strftime('%Y%m%d_%H%M')\n",
        "    fname       = '{!s}_{!s}km_eclipseObscuration'.format(date_str,int(height/1000))\n",
        "    fpath       = os.path.join(output_dir,fname)\n",
        "    print('Processing {!s}...'.format(fpath))\n",
        "\n",
        "    # Set up data dictionary.\n",
        "    dd          = OrderedDict()\n",
        "    dd['grid']  = loc_dict['grid']\n",
        "    dd['lat']   = loc_dict['lat']\n",
        "    dd['lon']   = loc_dict['lon']\n",
        "    dd['height']= loc_dict['height']\n",
        "#    locs        = loc_dict['loc']\n",
        "\n",
        "    # Eclipse Magnitude\n",
        "#    dd['obsc']  = np.array([eclipse_calc.calculate_obscuration(date,loc=loc) for loc in locs])\n",
        "    dates       = np.array(len(dd['lat'])*[date])\n",
        "    dd['obsc']  = eclipse_calc.calculate_obscuration(dates,dd['lat'],dd['lon'],height=dd['height'])\n",
        "#    dd['obsc']  = dd['lat'] # Useful for debugging plotting.\n",
        "\n",
        "    # Store into dataframe.\n",
        "    df          = pd.DataFrame(dd)\n",
        "    df          = df.set_index('grid')\n",
        "\n",
        "    # Save CSV Datafile.\n",
        "    csv_path    = fpath+'.csv'\n",
        "    with open(csv_path,'w') as fl:\n",
        "        fl.write('# Solar Eclipse Obscuration file for {!s}\\n'.format(date))\n",
        "    df.to_csv(csv_path,mode='a')\n",
        "\n",
        "    # Plot data.\n",
        "    map_prm = {}\n",
        "    if region == 'world':\n",
        "        # Map boundaries for the world\n",
        "        map_prm['llcrnrlon'] = -180.\n",
        "        map_prm['llcrnrlat'] = -90\n",
        "        map_prm['urcrnrlon'] = 180.\n",
        "        map_prm['urcrnrlat'] = 90.\n",
        "    else:\n",
        "        # Map boundaries for the United States\n",
        "        map_prm['llcrnrlon'] = -130.\n",
        "        map_prm['llcrnrlat'] =   20.\n",
        "        map_prm['urcrnrlon'] =  -60.\n",
        "        map_prm['urcrnrlat'] =   55.\n",
        "\n",
        "    vmin        = 0.\n",
        "    vmax        = 1.\n",
        "    cbar_ticks  = np.arange(0,1.1,0.1)\n",
        "\n",
        "    fig         = plt.figure(figsize=(12,10))\n",
        "    ax          = fig.add_subplot(111)\n",
        "    hmap        = eclipse_calc.maps.HamMap(date,date,ax,show_title=False,**map_prm)\n",
        "    hmap.overlay_gridsquares(label_precision=0,major_style={'color':'0.8','dashes':[1,1]})\n",
        "    hmap.overlay_gridsquare_data(dd['grid'],dd['obsc'],vmin=vmin,vmax=vmax,cbar_ticks=cbar_ticks,\n",
        "                zorder=5,cmap=cmap,cbar_shrink=0.5,cbar_label='Obscuration')\n",
        "\n",
        "    title       = '{!s} Height: {!s} km'.format(date.strftime('%d %b %Y %H%M UT'),height/1000.)\n",
        "    fontdict    = {'size':'x-large','weight':'bold'}\n",
        "    hmap.ax.text(0.5,1.025,title,fontdict=fontdict,transform=ax.transAxes,ha='center')\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(fpath+'.png',bbox_inches='tight')\n",
        "\n",
        "    plt.close(fig)\n",
        "\n",
        "    return fpath\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    output_dir  = 'drive/My Drive/output'\n",
        "    eclipse_calc.gen_lib.clear_dir(output_dir,php=True)\n",
        "\n",
        "    sDate   = datetime.datetime(2020,12,14,14)\n",
        "    eDate   = datetime.datetime(2020,12,14,18,30)\n",
        "#    sDate   = datetime.datetime(2017,8,21,18)\n",
        "#    eDate   = datetime.datetime(2017,8,21,19)\n",
        "    dt      = datetime.timedelta(minutes=5)\n",
        "\n",
        "    precision   = 4\n",
        "    height      = 300e3\n",
        "\n",
        "    loc_dict    = location_dict(precision=precision,height=height)\n",
        "\n",
        "    run_list    = []\n",
        "    cDate       = sDate\n",
        "    while cDate < eDate:\n",
        "        tmp = OrderedDict()\n",
        "        tmp['date']         = cDate\n",
        "        tmp['loc_dict']     = loc_dict\n",
        "        tmp['output_dir']   = output_dir\n",
        "        run_list.append(tmp)\n",
        "        cDate   += dt\n",
        "\n",
        "#    # Single Processor\n",
        "#    for run_dict in run_list:\n",
        "#        fpath = plot_eclipse_dict(run_dict)\n",
        "\n",
        "    with multiprocessing.Pool() as pool:\n",
        "        pool.map(plot_eclipse_dict,run_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}